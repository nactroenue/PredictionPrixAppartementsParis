# Pr√©diction des Prix des Appartements √† Paris üè°

## Objectif du Projet

L'objectif principal de ce projet est de d√©velopper des mod√®les de r√©gression avanc√©s pour pr√©dire les prix des appartements √† Paris. En utilisant des caract√©ristiques g√©ographiques, de localisation et de propri√©t√©s, nous cherchons √† comprendre les facteurs cl√©s qui influencent les prix immobiliers et √† fournir des pr√©dictions pr√©cises pour aider les acheteurs, les vendeurs et les professionnels de l'immobilier.

## Description des Fichiers

**config.py**

Contient les param√®tres globaux du projet, y compris les chemins des fichiers, les hyperparam√®tres des mod√®les et les configurations pour l'ing√©nierie des features et les visualisations.

<details><summary>Voir le code</summary>
  
```python

import os

# ============================================
#               Param√®tres G√©n√©raux
# ============================================

class GeneralSettings:
    RANDOM_SEED = 42
    TEST_SIZE = 0.2
    VALIDATION_SIZE = 0.2

# ============================================
#                  Chemins Fichiers
# ============================================

class FilePaths:
    DATA_FILE_PATH = os.getenv('DATA_FILE_PATH', 'C:/Users/33766/Downloads/Appartment Price Prediction/apartment_data.json')
    MODEL_SAVE_PATHS = {
        'Scaler': 'models/scaler.joblib',
        'RandomForest': 'models/RandomForest_model.joblib',
        'GradientBoosting': 'models/GradientBoosting_model.joblib',
        'ExtraTrees': 'models/ExtraTrees_model.joblib',
        'XGBoost': 'models/XGBoost_model.joblib',
        'LightGBM': 'models/LightGBM_model.joblib',
        'MLP': 'models/MLP_model.joblib',
        'DNN': 'models/best_dnn_model.keras',
        'Linear': 'models/Linear_model.joblib',
        'DecisionTree': 'models/DecisionTree_model.joblib',
        'Ensemble': 'models/best_ensemble_model.joblib'
    }
    PROCESSED_DATA_PATHS = {
        'X_train': 'processed/X_train.joblib',
        'y_train': 'processed/y_train.joblib',
        'X_test': 'processed/X_test.joblib',
        'y_test': 'processed/y_test.joblib'
    }

# ============================================
#        Grilles d'Hyperparam√®tres pour les Mod√®les
# ============================================

class HyperparameterGrids:
    EXTRA_TREES = {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    RANDOM_FOREST = {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    GRADIENT_BOOSTING = {
        'n_estimators': [100, 200, 300],
        'learning_rate': [0.01, 0.05, 0.1],
        'max_depth': [3, 5, 7],
        'min_samples_leaf': [1, 2, 4],
        'subsample': [0.7, 0.8, 0.9]
    }
    XGBOOST = {
        'n_estimators': [100, 200],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.05, 0.1],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.7, 0.8, 0.9]
    }
    LIGHTGBM = {
        'objective': ['regression'],
        'metric': ['rmse'],
        'boosting_type': ['gbdt'],
        'max_bin': [128, 255, 512],
        'num_leaves': [31, 61, 91],
        'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],
        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
        'reg_alpha': [0.0, 0.1, 0.5, 1.0],
        'reg_lambda': [0.0, 0.1, 0.5, 1.0],
        'min_split_gain': [0.0, 0.1, 0.2],
        'n_estimators': [100, 200, 300, 500, 1000]
    }

# ============================================
#         Poids de l'Ensemble pour le VotingRegressor
# ============================================

class EnsembleSettings:
    WEIGHTS = [0.4, 0.35, 0.15, 0.10]  # [RandomForest, GradientBoosting, XGBoost, LightGBM]

# ============================================
#        Param√®tres de S√©lection des Features
# ============================================

class FeatureSelectionParams:
    THRESHOLD = 0.001
    CORR_THRESHOLD = 0.9
    N_FEATURES = 30

# ============================================
#               Configuration de la Journalisation
# ============================================

class LoggingConfig:
    LEVEL = 'INFO'
    FORMAT = '%(asctime)s - %(levelname)s - %(message)s'

# ============================================
#            Param√®tres du R√©seau de Neurones
# ============================================

class NeuralNetworkSettings:
    EPOCHS = 500
    BATCH_SIZE = 32
    PATIENCE = 50
    LEARNING_RATE = [0.01, 0.005, 0.001]

# ============================================
#        Param√®tres d'Ing√©nierie des Features
# ============================================

class FeatureEngineering:
    SPATIAL_CLUSTERS = 10
    LANDMARKS = {
        'Eiffel_Tower': (2.2945, 48.8584),
        'Louvre_Museum': (2.3364, 48.8606),
        'Notre_Dame': (2.3499, 48.8530)
    }

# ============================================
#        Encodage des Features Cat√©gorielles
# ============================================

class EncodingFeatures:
    ONE_HOT_ENCODING_FEATURES = ['ville']
    TARGET_ENCODING_FEATURES = ['nom_quartier']

# ============================================
#        D√©finition des Features d'Interaction
# ============================================

class InteractionFeatures:
    DEFINITIONS = {
        'longitude_latitude_interaction': ['longitude', 'latitude'],
        'distance_city_center_piece_interaction': ['distance_from_center', 'piece'],
        'distance_to_Eiffel_Tower_bathroom_interaction': ['distance_to_Eiffel_Tower', 'bathroom'],
        'distance_to_Louvre_Museum_bathroom_interaction': ['distance_to_Louvre_Museum', 'bathroom']
    }

# ============================================
#        Gestion des Formes G√©ographiques
# ============================================

class GeoShapeConfig:
    INCLUDE_GEO_SHAPE = False
    EXCLUDED_FEATURES = ['ref']
```
</details>

**2. data_preparation.py**

Script pour charger, pr√©parer et diviser les donn√©es. Inclut l'extraction des coordonn√©es g√©ographiques, l'encodage des variables cat√©gorielles et la cr√©ation de la colonne cible average_price.

<details><summary>Voir le code</summary>
  
```python

import pandas as pd
import numpy as np
import logging
from sklearn.model_selection import train_test_split
from config import (
    GeneralSettings,
    FeatureSelectionParams,
    EncodingFeatures,
    FeatureEngineering
)
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import RFE
from category_encoders import TargetEncoder
from geopy.distance import geodesic
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
from feature_engineering import (
    calculate_vif,
    process_for_multicollinearity,
    create_interaction_terms,
    calculate_distance_to_landmarks,
    SpatialClusterAdder,
    scale_spatial_features
)
import joblib
import os
from typing import Tuple

def extract_coordinates(df):
    """
    Extrait la longitude et la latitude de la colonne 'geo_point_2d',
    en rendant ces coordonn√©es disponibles en tant que features s√©par√©es.
    
    Param√®tres :
        df (pd.DataFrame): DataFrame avec une colonne 'geo_point_2d' contenant les informations de coordonn√©es.
        
    Returns:
        pd.DataFrame: DataFrame avec les colonnes 'latitude' et 'longitude' extraites.
    """
    if 'geo_point_2d' in df.columns:
        # V√©rifier si 'geo_point_2d' est un dictionnaire ou une liste/tuple et extraire en cons√©quence
        if isinstance(df['geo_point_2d'].iloc[0], dict):
            df['longitude'] = df['geo_point_2d'].apply(lambda x: x.get('lon') if isinstance(x, dict) else np.nan)
            df['latitude'] = df['geo_point_2d'].apply(lambda x: x.get('lat') if isinstance(x, dict) else np.nan)
        elif isinstance(df['geo_point_2d'].iloc[0], (list, tuple)):
            df['latitude'] = df['geo_point_2d'].apply(lambda x: x[0] if isinstance(x, (list, tuple)) and len(x) >= 2 else np.nan)
            df['longitude'] = df['geo_point_2d'].apply(lambda x: x[1] if isinstance(x, (list, tuple)) and len(x) >= 2 else np.nan)
        else:
            logging.warning("Format inattendu pour 'geo_point_2d'. Dictionnaire ou liste/tuple attendu.")
            df['longitude'] = np.nan
            df['latitude'] = np.nan
        # Supprimer la colonne d'origine 'geo_point_2d' apr√®s extraction
        df = df.drop(columns=['geo_point_2d'], errors='ignore')
    else:
        logging.warning("Colonne 'geo_point_2d' non trouv√©e dans le DataFrame. 'longitude' et 'latitude' ne seront pas cr√©√©es.")
        df['longitude'] = np.nan
        df['latitude'] = np.nan
    
    return df

# Transformateur personnalis√© pour le calcul des distances
class DistanceCalculator(BaseEstimator, TransformerMixin):
    def __init__(self, center_coordinates: tuple):
        self.center_coordinates = center_coordinates

    def fit(self, X, y=None):
        return self

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        X = X.copy()
        X['distance_from_center'] = X.apply(
            lambda row: np.sqrt(
                (row['longitude'] - self.center_coordinates[0])**2 + 
                (row['latitude'] - self.center_coordinates[1])**2
            ),
            axis=1
        )
        return X

# Transformateur personnalis√© pour les distances aux monuments
class LandmarkDistanceCalculator(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.landmarks = FeatureEngineering.LANDMARKS 

    def fit(self, X, y=None):
        return self

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        return calculate_distance_to_landmarks(X, self.landmarks)

# Transformateur personnalis√© pour la s√©lection de features (VIF)
class VIFSelector(BaseEstimator, TransformerMixin):
    def __init__(self, threshold: float = 10.0, protected_features: list = None):
        self.threshold = threshold
        self.protected_features = protected_features if protected_features else []
        self.features_to_keep = []

    def fit(self, X, y=None):
        return process_for_multicollinearity(X, threshold=self.threshold, protected_features=self.protected_features)

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        return X[self.features_to_keep + ['average_price']] if 'average_price' in X.columns else X[self.features_to_keep]

# Pipeline de s√©lection des features
def feature_selection_pipeline(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, n_features: int = 30) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Applique la m√©thode RFE (Elimination R√©cursive des Features) pour la s√©lection des features.
    
    Param√®tres :
        X_train (pd.DataFrame): Features d'entra√Ænement.
        y_train (pd.Series): Variable cible d'entra√Ænement.
        X_test (pd.DataFrame): Features de test.
        n_features (int): Nombre de features √† s√©lectionner.
    
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: Features s√©lectionn√©es pour l'entra√Ænement et le test.
    """
    rf = RandomForestRegressor(n_estimators=100, random_state=GeneralSettings.RANDOM_SEED)
    rfe = RFE(estimator=rf, n_features_to_select=n_features, step=10, n_jobs=-1)
    rfe.fit(X_train, y_train)
    selected_features = X_train.columns[rfe.support_]
    logging.info(f"Selected {len(selected_features)} features s√©lectionn√©es avec la m√©thode RFE.")
    return X_train[selected_features], X_test[selected_features]

def encode_binary_column(df):
    """
    Encode la colonne 'meuble_txt' en une colonne binaire 'meuble_binary' indiquant
    si l'appartement est meubl√© (1) ou non (0).
    """
    if 'meuble_txt' in df.columns:
        df['meuble_binary'] = df['meuble_txt'].apply(lambda x: 1 if x == 'meubl√©' else 0)
        # Supprimer la colonne 'meuble_txt' apr√®s l'encodage
        df = df.drop(columns=['meuble_txt'], errors='ignore')
    else:
        logging.warning("Colonne 'meuble_txt' non trouv√©e dans le DataFrame. 'meuble_binary' ne sera pas cr√©√©e.")
        df['meuble_binary'] = 0  # Attribuer une valeur par d√©faut ou g√©rer en cons√©quence
    return df

def create_target_column(df):
    """
    Ajoute une colonne cible 'prix_moyen' calcul√©e comme la moyenne des colonnes de prix 'max' et 'min'.
    """
    # S'assurer que 'max' et 'min' sont des floats pour une moyenne correcte
    df['max'] = pd.to_numeric(df['max'], errors='coerce')
    df['min'] = pd.to_numeric(df['min'], errors='coerce')
    df['average_price'] = (df['max'] + df['min']) / 2
    return df

def load_and_prepare_data(file_path: str, center_coordinates: tuple) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:
    """
    Charger, pr√©traiter et diviser les donn√©es en ensembles d'entra√Ænement et de test en utilisant des Pipelines.
    
    Param√®tres :
        file_path (str): Chemin vers le fichier de donn√©es JSON.
        center_coordinates (tuple): (longitude, latitude) du centre-ville
    
    Returns:
        Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]: Donn√©es d'entra√Ænement et de test pr√©trait√©es.
    """
    if not os.path.exists(file_path):
        logging.error(f"Le fichier {file_path} n'existe pas.")
        raise FileNotFoundError(f"Le fichier {file_path} n'existe pas.")
    
    try:
        df = pd.read_json(file_path, orient="columns")
        df = extract_coordinates(df)  # S'assurer que les coordonn√©es sont extraites
        df = encode_binary_column(df)  # Convertir 'meuble_txt' en 'meuble_binary'
        df = create_target_column(df)  # Cr√©er 'prix_moyen' comme variable cible
        logging.info(f"Loaded data with shape: {df.shape} and columns: {df.columns.tolist()}")
    except ValueError as e:
        logging.error(f"Erreur lors de la lecture du fichier JSON : {e}")
        raise

    # V√©rifier que 'prix_moyen' a bien √©t√© cr√©√©e
    if 'average_price' not in df.columns:
        logging.error("La variable cible 'prix_moyen' n'a pas pu √™tre cr√©√©e.")
        raise KeyError("La variable cible 'prix_moyen' est manquante.")

    # Diviser les donn√©es apr√®s extraction des coordonn√©es et encodage
    train_df, test_df = train_test_split(df, test_size=GeneralSettings.TEST_SIZE, random_state=GeneralSettings.RANDOM_SEED)
    logging.info(f"Forme des donn√©es d'entra√Ænement : {train_df.shape}, Forme des donn√©es de test : {test_df.shape}")

    # D√©finir les pipelines de pr√©traitement pour les donn√©es num√©riques et cat√©gorielles
    numerical_features = ['piece', 'meuble_binary', 'longitude', 'latitude']
    categorical_features = EncodingFeatures.ONE_HOT_ENCODING_FEATURES + EncodingFeatures.TARGET_ENCODING_FEATURES

    # Journaliser les colonnes disponibles dans df_entrainement pour v√©rifier que toutes les colonnes requises sont pr√©sentes
    logging.debug(f"Colonnes dans les donn√©es d'entra√Ænement avant la configuration du pipeline : {train_df.columns.tolist()}")

    # Poursuivre avec la configuration du reste du pipeline et les transformations pr√©vues
    numerical_pipeline = Pipeline(steps=[
        ('scaler', StandardScaler())
    ])
    
    # Pipeline cat√©goriel
    categorical_pipeline = Pipeline(steps=[
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
    ])
    
    # Pr√©processeur combin√©
    preprocessor = ColumnTransformer(transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features)
    ], remainder='drop')

    full_pipeline = Pipeline(steps=[
        ('preprocessing', preprocessor)
    ])

    # Ajuster et transformer les donn√©es d'entra√Ænement
    logging.info("Ajustement et transformation des donn√©es d'entra√Ænement...")
    try:
        processed_train_array = full_pipeline.fit_transform(train_df)
        feature_names = numerical_features + list(full_pipeline.named_steps['preprocessing'].transformers_[1][1].get_feature_names_out(categorical_features))
        processed_train_df = pd.DataFrame(processed_train_array, columns=feature_names)
        logging.info(f"Forme des donn√©es d'entra√Ænement trait√©es : {processed_train_df.shape}")
    except Exception as e:
        logging.error(f"Erreur lors de l'ajustement et de la transformation du pipeline sur les donn√©es d'entra√Ænement : {e}")
        raise
    
    # Transformer les donn√©es de test
    logging.info("Transformation des donn√©es de test...")
    try:
        processed_test_array = full_pipeline.transform(test_df)
        processed_test_df = pd.DataFrame(processed_test_array, columns=feature_names)
        logging.info(f"Forme des donn√©es de test trait√©es : {processed_test_df.shape}")
    except Exception as e:
        logging.error(f"Erreur lors de la transformation du pipeline sur les donn√©es de test : {e}")
        raise
    
    # S√©parer la variable cible
    y_train = train_df['average_price'].reset_index(drop=True)
    y_test = test_df['average_price'].reset_index(drop=True)
    logging.info("S√©paration des features et de la variable cible.")
    
    return processed_train_df, y_train, processed_test_df, y_test
```

</details>

**3. feature_engineering.py**

G√®re l'ing√©nierie des features, notamment le calcul des distances aux monuments, la cr√©ation d'interactions entre les variables et la r√©duction de la multicolin√©arit√© avec des m√©thodes comme RFE.classes.

<details><summary>Voir le code</summary>

```python

import pandas as pd
import numpy as np
from statsmodels.stats.outliers_influence import variance_inflation_factor
import logging
from geopy.distance import geodesic
from sklearn.cluster import KMeans
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler

def calculate_vif(df: pd.DataFrame, features: list) -> pd.DataFrame:
    """Calculer le VIF pour chaque feature de la liste."""
    vif_data = pd.DataFrame()
    vif_data["Feature"] = features
    vif_data["VIF"] = [variance_inflation_factor(df[features].values, i) for i in range(len(features))]
    return vif_data

def process_for_multicollinearity(
    df: pd.DataFrame, 
    threshold: float = 10.0, 
    protected_features: list = None
) -> pd.DataFrame:
    """
    Supprimer les features multicolin√©aires en fonction du VIF.
    
    Param√®tres:
        df (pd.DataFrame): Input DataFrame.
        threshold (float): Seuil de VIF pour supprimer les features.
        protected_features (list): Features √† prot√©ger contre la suppression.
    
    Returns:
        pd.DataFrame: DataFrame avec une multicolin√©arit√© r√©duite.
    """
    if protected_features is None:
        protected_features = []
    
    df_numeric = df.select_dtypes(include=[np.number]).copy()
    logging.info(f"Colonnes num√©riques avant calcul du VIF : {df_numeric.columns.tolist()}")

    # Exclure la variable cible si pr√©sente
    target = 'average_price'
    if target in df_numeric.columns:
        df_numeric = df_numeric.drop(columns=[target])
        logging.info(f"Exclusion de '{target}' du calcul du VIF.")

    # G√©rer les valeurs NaN ou infinies
    df_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_numeric.fillna(df_numeric.mean(), inplace=True)

    # Supprimer les colonnes √† variance z√©ro
    zero_var_cols = df_numeric.columns[df_numeric.var() == 0].tolist()
    if zero_var_cols:
        df_numeric.drop(columns=zero_var_cols, inplace=True)
        logging.info(f"Colonnes √† variance z√©ro supprim√©es : {zero_var_cols}")

    if df_numeric.empty:
        logging.error("DataFrame vide apr√®s les √©tapes de nettoyage.")
        return df_numeric

    features = df_numeric.columns.tolist()
    dropped_features = []

    while True:
        vif_df = calculate_vif(df_numeric, features)
        max_vif = vif_df['VIF'].max()
        if max_vif > threshold:
            feature_to_drop = vif_df.loc[vif_df['VIF'].idxmax(), 'Feature']
            if feature_to_drop in protected_features:
                logging.info(f"Feature prot√©g√©e '{feature_to_drop}' avec un VIF √©lev√© ({max_vif}) et ne sera pas supprim√©e.")
                break
            features.remove(feature_to_drop)
            dropped_features.append(feature_to_drop)
            logging.info(f"Suppression de '{feature_to_drop}' avec VIF={max_vif:.2f}")
        else:
            break

    logging.info(f"Features supprim√©es en raison d'un VIF √©lev√© : {dropped_features}")
    logging.info(f"Features finales apr√®s traitement du VIF : {features}")
    return df[features + [target]] if target in df.columns else df[features]

def create_interaction_terms(df: pd.DataFrame, features: list) -> pd.DataFrame:
    """
    Cr√©er des termes d'interaction entre les features sp√©cifi√©es.

    Param√®tres :
        df (pd.DataFrame): Input DataFrame.
        features (list): Liste des noms de features √† interagir.

    Returns:
        pd.DataFrame: DataFrame avec les termes d'interaction ajout√©s.
    """
    for i in range(len(features)):
        for j in range(i+1, len(features)):
            feature_name = f"{features[i]}_x_{features[j]}"
            df[feature_name] = df[features[i]] * df[features[j]]
            logging.debug(f"Cr√©ation du terme d'interaction : {feature_name}")
    return df

def calculate_distance_to_landmarks(df: pd.DataFrame, landmarks: dict) -> pd.DataFrame:
    """
    Calculer les distances entre chaque appartement et des monuments pr√©d√©finis.
    
    Parameters:
        df (pd.DataFrame): Input DataFrame avec les colonnes 'latitude' et 'longitude'.
        landmarks (dict): Dictionnaire de monuments avec les noms comme cl√©s et les tuples (latitude, longitude) comme valeurs.
    
    Returns:
        pd.DataFrame: DataFrame avec de nouvelles colonnes de distance pour chaque monument.
    """
    for landmark, coords in landmarks.items():
        column_name = f"distance_au_{landmark}"
        df[column_name] = df.apply(
            lambda row: geodesic((row['latitude'], row['longitude']), coords).kilometers 
            if pd.notnull(row['latitude']) and pd.notnull(row['longitude']) else np.nan,
            axis=1
        )
        logging.debug(f"Calcul de la distance au {landmark}")
    return df

class SpatialClusterAdder(BaseEstimator, TransformerMixin):
    """
    Transformateur personnalis√© pour ajouter des clusters spatiaux √† une DataFrame en utilisant le clustering KMeans.
    
    Param√®tres :
        n_clusters (int): Nombre de clusters pour KMeans.
        random_state (int): Graine al√©atoire pour la reproductibilit√©.
    """
    def __init__(self, n_clusters: int = 10, random_state: int = 42):
        self.n_clusters = n_clusters
        self.random_state = random_state
        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=self.random_state)

    def fit(self, X, y=None):
        if 'longitude' in X.columns and 'latitude' in X.columns:
            coords = X[['longitude', 'latitude']]
            self.kmeans.fit(coords)
        else:
            raise ValueError("Colonnes 'longitude' et 'latitude' attendues pour le clustering.")
        return self

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        coords = X[['longitude', 'latitude']]
        X = X.copy()
        X['spatial_cluster'] = self.kmeans.predict(coords)
        logging.debug(f"Ajout de 'cluster_spatial' avec {self.n_clusters} clusters")
        return X

def scale_spatial_features(df: pd.DataFrame, features: list) -> pd.DataFrame:
    """
    Normaliser les features spatiales sp√©cifi√©es en utilisant StandardScaler.
    
    Param√®tres :
        df (pd.DataFrame): Input DataFrame.
        features (list): Liste des noms de features √† normaliser.
    
    Returns:
        pd.DataFrame: DataFrame avec les features normalis√©es.
    """
    scaler = StandardScaler()
    df[features] = scaler.fit_transform(df[features])
    logging.debug(f"Normalisation des features spatiales : {features}")
    return df

```

</details>

**4. model_training.py**

Script pour entra√Æner et √©valuer les mod√®les de r√©gression, y compris le r√©glage des hyperparam√®tres et l'utilisation d'un mod√®le d'ensemble.

<details><summary>Voir le code</summary>

```python

import pandas as pd
import numpy as np
from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import (
    RandomForestRegressor,
    GradientBoostingRegressor,
    ExtraTreesRegressor,
    VotingRegressor
)
from sklearn.tree import DecisionTreeRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
import joblib
import logging
import xgboost as xgb
import lightgbm as lgb
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers
from utils import Metrics, Visualization, TensorFlowMetrics
from config import (
    GeneralSettings,
    FilePaths,
    HyperparameterGrids,
    NeuralNetworkSettings,
    EnsembleSettings
)
from typing import Tuple, Dict, Any
from visualization import Visualization
import os


def train_and_evaluate_models(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series) -> Tuple[Dict[str, float], Dict[str, np.ndarray]]:
    """
    Entra√Æner et √©valuer plusieurs mod√®les de r√©gression avec r√©glage des hyperparam√®tres.

    Param√®tres:
        X_train (pd.DataFrame): Caract√©ristiques d'entra√Ænement.
        y_train (pd.Series): Cible d'entra√Ænement.
        X_test (pd.DataFrame): Caract√©ristiques de test.
        y_test (pd.Series): Cible de test.

    Returns:
        Tuple[Dict[str, float], Dict[str, np.ndarray]]: Scores RMSE et pr√©dictions des mod√®les.
    """
    logging.info("D√©but de l'entra√Ænement et de l'√©valuation des mod√®les...")

    # Initialiser et sauvegarder le scaler
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    joblib.dump(scaler, FilePaths.MODEL_SAVE_PATHS['Scaler'])
    logging.info(f"Scaler ajust√© et sauvegard√© √† {FilePaths.MODEL_SAVE_PATHS['Scaler']}.")



    # Cr√©er des caract√©ristiques polynomiales
    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
    X_train_poly = poly.fit_transform(X_train_scaled)
    X_test_poly = poly.transform(X_test_scaled)
    feature_names = poly.get_feature_names_out(input_features=X_train.columns)
    logging.info("Caract√©ristiques polynomiales cr√©√©es.")

    # D√©finir les mod√®les
    models = {
        'Linear': LinearRegression(),
        'DecisionTree': DecisionTreeRegressor(random_state=GeneralSettings.RANDOM_SEED),
        'RandomForest': RandomForestRegressor(random_state=GeneralSettings.RANDOM_SEED),
        'GradientBoosting': GradientBoostingRegressor(random_state=GeneralSettings.RANDOM_SEED),
        'ExtraTrees': ExtraTreesRegressor(random_state=GeneralSettings.RANDOM_SEED),
        'XGBoost': xgb.XGBRegressor(random_state=GeneralSettings.RANDOM_SEED, objective='reg:squarederror'),
        'LightGBM': lgb.LGBMRegressor(random_state=GeneralSettings.RANDOM_SEED),
        'MLP': MLPRegressor(random_state=GeneralSettings.RANDOM_SEED, max_iter=500)
    }

    # Grilles d'hyperparam√®tres
    param_grids = {
        'RandomForest': HyperparameterGrids.RANDOM_FOREST,
        'GradientBoosting': HyperparameterGrids.GRADIENT_BOOSTING,
        'ExtraTrees': HyperparameterGrids.EXTRA_TREES,
        'XGBoost': HyperparameterGrids.XGBOOST,
        'LightGBM': HyperparameterGrids.LIGHTGBM
    }

    model_rmse_scores = {}
    model_predictions = {}
    trained_models = {}

    # Cr√©er le r√©pertoire de graphiques
    plots_dir = 'C:/Users/33766/models/plots'
    os.makedirs(plots_dir, exist_ok=True)
    

    # Entra√Æner les mod√®les avec r√©glage des hyperparam√®tres
    for name, model in models.items():
        logging.info(f"Entra√Ænement du mod√®le: {name}")
        if name in param_grids:
            best_params, best_model = tune_model(model, param_grids[name], X_train_scaled, y_train)
            logging.info(f"Meilleurs param√®tres pour {name}: {best_params}")
        else:
            # Validation crois√©e pour les mod√®les sans hyperparam√®tres
            cv = KFold(n_splits=5, shuffle=True, random_state=GeneralSettings.RANDOM_SEED)
            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)
            mean_rmse = -cv_scores.mean()
            std_rmse = cv_scores.std()
            logging.info(f"{name} CV RMSE: {mean_rmse:.4f} ¬± {std_rmse:.4f}")
            model.fit(X_train_scaled, y_train)
            best_model = model

        # Pr√©dictions et √©valuation
        y_pred = best_model.predict(X_test_scaled)
        test_rmse = Metrics.rmse(y_test, y_pred)
        model_rmse_scores[name] = test_rmse
        model_predictions[name] = y_pred
        logging.info(f"RMSE du mod√®le {name} sur le test: {test_rmse:.4f}")

        # Tracer les pr√©dictions vs r√©el
        pred_plot_path = os.path.join(plots_dir, f"{name}_predictions.png")
        Visualization.plot_predictions(y_test, y_pred, name, save_path=pred_plot_path)

        # Tracer les r√©sidus
        resid_plot_path = os.path.join(plots_dir, f"{name}_residuals.png")
        Visualization.plot_residuals(y_test, y_pred, name, save_path=resid_plot_path)

        # Tracer l'importance des caract√©ristiques si applicable
        if hasattr(best_model, 'feature_importances_') or hasattr(best_model, "coef_"):
            save_path = os.path.join(plots_dir, f"{name}_feature_importance.png")
            Visualization.plot_feature_importance(
                best_model,
                feature_names,
                name,
                save_path=save_path,
                top_n=10
            )

        # Sauvegarder le mod√®le
        joblib.dump(best_model, FilePaths.MODEL_SAVE_PATHS[name])
        logging.info(f"{name} model saved to {FilePaths.MODEL_SAVE_PATHS[name]}.")

        trained_models[name] = best_model

    # Entra√Æner le r√©seau de neurones profond (DNN)
    dnn_rmse, dnn_preds, dnn_model = build_and_train_dnn(
        X_train_poly, y_train, X_test_poly, y_test, input_shape=X_train_poly.shape[1]
    )
    model_rmse_scores['DNN'] = dnn_rmse
    model_predictions['DNN'] = dnn_preds
    dnn_model.save(FilePaths.MODEL_SAVE_PATHS['DNN'])
    logging.info(f"Mod√®le DNN sauvegard√© √† {FilePaths.MODEL_SAVE_PATHS['DNN']}.")

    # Tracer les pr√©dictions vs r√©el pour DNN
    dnn_pred_plot_path = os.path.join(plots_dir, "DNN_predictions.png")
    Visualization.plot_predictions(y_test, dnn_preds, "DNN", save_path=dnn_pred_plot_path)

    # Tracer les r√©sidus pour DNN
    dnn_resid_plot_path = os.path.join(plots_dir, "DNN_residuals.png")
    Visualization.plot_residuals(y_test, dnn_preds, "DNN", save_path=dnn_resid_plot_path)

    # Entra√Æner l'ensemble
    ensemble_rmse, ensemble_preds, ensemble_model = build_ensemble_model(trained_models, X_train_scaled, y_train, X_test_scaled, y_test)
    model_rmse_scores['Ensemble'] = ensemble_rmse
    model_predictions['Ensemble'] = ensemble_preds
    joblib.dump(ensemble_model, FilePaths.MODEL_SAVE_PATHS['Ensemble'])
    logging.info(f"Mod√®le Ensemble sauvegard√© √† {FilePaths.MODEL_SAVE_PATHS['Ensemble']}.")

    # Tracer les pr√©dictions vs r√©el pour l'ensemble
    ensemble_pred_plot_path = os.path.join(plots_dir, "Ensemble_predictions.png")
    Visualization.plot_predictions(y_test, ensemble_preds, "Ensemble", save_path=ensemble_pred_plot_path)

    # Tracer les r√©sidus pour l'ensemble
    ensemble_resid_plot_path = os.path.join(plots_dir, "Ensemble_residuals.png")
    Visualization.plot_residuals(y_test, ensemble_preds, "Ensemble", save_path=ensemble_resid_plot_path)

    # Tracer l'importance des caract√©ristiques pour l'ensemble si applicable
    if hasattr(ensemble_model, 'feature_importances_') or hasattr(ensemble_model, "coef_"):
        ensemble_feat_imp_path = os.path.join(plots_dir, "Ensemble_feature_importance.png")
        logging.info(f"Tentative de trac√© de l'importance des caract√©ristiques pour l'ensemble")
        Visualization.plot_feature_importance(
            ensemble_model,
            feature_names,
            "Ensemble",
            save_path=ensemble_feat_imp_path,
            top_n=10
        )
    else:
        logging.info(f"Pas d'importance des caract√©ristiques ou de coefficients √† tracer pour l'ensemble.")

    # Enregistrer les scores RMSE finaux
    logging.info("Scores RMSE finaux des mod√®les:")
    for model_name, rmse_score in model_rmse_scores.items():
        logging.info(f"{model_name}: RMSE = {rmse_score:.4f}")

     # G√©n√©rer le rapport automatis√©
    try:
        Visualization.generate_automated_report(
            rmse_scores=model_rmse_scores,
            model_predictions=model_predictions,
            y_test=y_test,
            report_path="C:/Users/33766/models/automated_model_report.html",
            feature_names=feature_names.tolist(),
        )
        logging.info("Rapport automatis√© g√©n√©r√© avec succ√®s.")
    except Exception as e:
        logging.error(f"√âchec de la g√©n√©ration du rapport automatis√©: {e}")

    return model_rmse_scores, model_predictions


def tune_model(model: Any, param_grid: dict, X_train: np.ndarray, y_train: pd.Series) -> Tuple[dict, Any]:
    """
    Effectuer le r√©glage des hyperparam√®tres √† l'aide de RandomizedSearchCV.

    Param√®tres:
        model (Any): Estimateur de Scikit-learn
        param_grid (dict): Grille d'hyperparam√®tres.
        X_train (np.ndarray): Caract√©ristiques d'entra√Ænement.
        y_train (pd.Series): Cible d'entra√Ænement.

    Returns:
        Tuple[dict, Any]: Meilleurs param√®tres et meilleur estimateur.
    """
    search = RandomizedSearchCV(
        estimator=model,
        param_distributions=param_grid,
        n_iter=50,
        scoring='neg_root_mean_squared_error',
        cv=5,
        random_state=GeneralSettings.RANDOM_SEED,
        n_jobs=-1
    )
    search.fit(X_train, y_train)
    logging.info(f"RandomizedSearchCV termin√© pour {model.__class__.__name__}")
    return search.best_params_, search.best_estimator_


def build_and_train_dnn(X_train: np.ndarray, y_train: pd.Series, X_test: np.ndarray, y_test: pd.Series, input_shape: int) -> Tuple[float, np.ndarray, keras.Model]:
    """
    Construction, entra√Ænement et √©valuation un r√©seau de neurones profond (DNN).

    Param√®tres:
        X_train (np.ndarray): Caract√©ristiques d'entra√Ænement avec caract√©ristiques polynomiales.
        y_train (pd.Series): Cible d'entra√Ænement.
        X_test (np.ndarray): Caract√©ristiques de test avec caract√©ristiques polynomiales.
        y_test (pd.Series): Cible de test.
        input_shape (int): Nombre de caract√©ristiques d'entr√©e.

    Retourne:
        Tuple[float, np.ndarray, keras.Model]: Meilleur RMSE, meilleures pr√©dictions et meilleur mod√®le.
    """
    best_rmse = float('inf')
    best_model = None
    best_lr = None
    best_y_pred = None

    for lr in NeuralNetworkSettings.LEARNING_RATE:
        logging.info(f"Entra√Ænement du DNN avec un taux d'apprentissage de: {lr}")
        model = keras.Sequential([
            layers.Input(shape=(input_shape,)),
            layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
            layers.Dropout(0.5),
            layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
            layers.Dropout(0.5),
            layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
            layers.Dropout(0.3),
            layers.BatchNormalization(),
            layers.Dense(1)
        ])

        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=lr),
            loss=TensorFlowMetrics.root_mean_squared_error
        )

        early_stopping = keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=NeuralNetworkSettings.PATIENCE,
            restore_best_weights=True
        )
        lr_scheduler = keras.callbacks.LearningRateScheduler(adjusted_scheduler)

        history = model.fit(
            X_train, y_train,
            validation_split=0.2,
            epochs=NeuralNetworkSettings.EPOCHS,
            batch_size=NeuralNetworkSettings.BATCH_SIZE,
            callbacks=[early_stopping, lr_scheduler],
            verbose=0
        )

        y_pred = model.predict(X_test).flatten()
        current_rmse = Metrics.rmse(y_test, y_pred)
        logging.info(f"DNN avec LR={lr} a obtenu un RMSE={current_rmse:.4f}")

        if current_rmse < best_rmse:
            best_rmse = current_rmse
            best_model = model
            best_lr = lr
            best_y_pred = y_pred

    logging.info(f"Meilleur taux d'apprentissage DNN: {best_lr} avec RMSE: {best_rmse:.4f}")
    return best_rmse, best_y_pred, best_model


def adjusted_scheduler(epoch: int, current_lr: float) -> float:
    """
    Ajustement le taux d'apprentissage apr√®s un certain nombre d'√©poques.

    Param√®tres:
        epoch (int): Num√©ro de l'√©poque actuelle.
        current_lr (float): Taux d'apprentissage actuel.

    Retourne:
        float: Taux d'apprentissage mis √† jour.
    """
    if epoch >= 30:
        return current_lr * np.exp(-0.005 * (epoch - 30))
    return current_lr


def build_ensemble_model(trained_models: Dict[str, Any], X_train: np.ndarray, y_train: pd.Series, X_test: np.ndarray, y_test: pd.Series) -> Tuple[float, np.ndarray, VotingRegressor]:
    """
    Construire et √©valuer un mod√®le d'ensemble √† l'aide de VotingRegressor.

    Param√®tres:
        trained_models (Dict[str, Any]): Dictionnaire de mod√®les entra√Æn√©s.
        X_train (np.ndarray): Caract√©ristiques d'entra√Ænement mises √† l'√©chelle.
        y_train (pd.Series): Cible d'entra√Ænement.
        X_test (np.ndarray): Caract√©ristiques de test mises √† l'√©chelle.
        y_test (pd.Series): Cible de test.

    Retourne:
        Tuple[float, np.ndarray, VotingRegressor]: RMSE de l'ensemble, pr√©dictions et mod√®le d'ensemble.
    """
    ensemble_estimators = [
        ('rf', trained_models.get('RandomForest')),
        ('gb', trained_models.get('GradientBoosting')),
        ('xgb', trained_models.get('XGBoost')),
        ('lgbm', trained_models.get('LightGBM'))
    ]
    
    # Supprimer les estimateurs None si pr√©sents
    ensemble_estimators = [est for est in ensemble_estimators if est[1] is not None]
    
    if not ensemble_estimators:
        logging.error("Aucun mod√®le valide disponible pour l'ensemble.")
        raise ValueError("Aucun mod√®le valide disponible pour l'ensemble.")
    
    ensemble_model = VotingRegressor(
        estimators=ensemble_estimators,
        weights=EnsembleSettings.WEIGHTS
    )
    
    ensemble_model.fit(X_train, y_train)
    ensemble_pred = ensemble_model.predict(X_test)
    ensemble_rmse = Metrics.rmse(y_test, ensemble_pred)
    logging.info(f"Ensemble Model RMSE: {ensemble_rmse:.4f}")
    
    return ensemble_rmse, ensemble_pred, ensemble_model

```
</details>


**5. visualization.py**

Contient des fonctions pour g√©n√©rer des graphiques et des rapports automatis√©s, tels que l'importance des caract√©ristiques, les pr√©dictions vs r√©el et la distribution des r√©sidus.

<details> <summary>Voir le code</summary>

```python

import os
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import logging
from jinja2 import Environment, FileSystemLoader
import shutil


class Visualization:
    """Classe utilitaire pour cr√©er des visualisations, g√©n√©rer des rapports et configurer des tableaux de bord."""
    
    @staticmethod
    def plot_feature_importance(model, feature_names, model_name, save_path, top_n=10):
        """Trace et enregistre les N meilleures importances ou coefficients des caract√©ristiques avec des valeurs affich√©es."""
        if hasattr(model, "feature_importances_"):
            # Pour les mod√®les bas√©s sur les arbres avec feature_importances_
            importances = model.feature_importances_
            indices = np.argsort(importances)[-top_n:][::-1]
            top_features = [feature_names[i] for i in indices]
            top_importances = importances[indices]

            plt.figure(figsize=(12, 8))
            plt.title(f"Top {top_n} Importances des Caract√©ristiques - {model_name}")
            bars = plt.barh(range(top_n), top_importances, align="center")
            plt.yticks(range(top_n), top_features)
            plt.xlabel("Importance")
            plt.tight_layout()

            # Annoter chaque barre avec la valeur de l'importance, ajust√©e pour les grandes valeurs
            for bar, importance in zip(bars, top_importances):
                if importance > 1:
                    # Affichage des grandes valeurs en notation scientifique si n√©cessaire
                    formatted_value = f'{importance:.0f}' if importance < 1e3 else f'{importance:.2e}'
                else:
                    formatted_value = f'{importance:.3f}'
                
                plt.text(
                    bar.get_width(), bar.get_y() + bar.get_height()/2,
                    formatted_value, va='center', ha='left'
                )

            plt.savefig(save_path)
            plt.close()
            logging.info(f"Graphique d'importance des caract√©ristiques pour {model_name} dans {save_path}. Affichage des {top_n} meilleures caract√©ristiques.")
        
        elif hasattr(model, "coef_"):
            logging.debug(f"G√©n√©ration du graphique des coefficients pour {model_name}")
            # Pour les mod√®les lin√©aires avec coef_
            coefficients = model.coef_
            if coefficients is None or len(coefficients) == 0:
                logging.warning(f"Aucun coefficient trouv√© pour {model_name}. Passage du graphique.")
                return
            indices = np.argsort(np.abs(coefficients))[-top_n:][::-1]  # Trier par valeur absolue des coefficients
            top_features = [feature_names[i] for i in indices]
            top_coefficients = coefficients[indices]

            plt.figure(figsize=(12, 8))
            plt.title(f"Top {top_n} Coefficients des Caract√©ristiques - {model_name}")
            bars = plt.barh(range(top_n), top_coefficients, align="center")
            plt.yticks(range(top_n), top_features)
            plt.xlabel("Valeur du Coefficient")
            plt.tight_layout()

            for bar, coef in zip(bars, top_coefficients):
                formatted_coef = f'{coef:.2f}' if np.abs(coef) < 1e3 else f'{coef:.2e}'
                plt.text(
                    bar.get_width(), bar.get_y() + bar.get_height()/2,
                    formatted_coef, va='center', ha='left'
                )

            plt.savefig(save_path)
            plt.close()
            logging.info(f"Graphique des coefficients pour {model_name} enregistr√© dans {save_path}. Affichage des {top_n} meilleurs coefficients.")
        
        else:
            logging.warning(f"{model_name} ne prend pas en charge l'affichage des importances ou des coefficients des caract√©ristiques.")
    
    @staticmethod
    def generate_automated_report(
        rmse_scores, model_predictions, y_test, report_path="C:/Users/33766/Downloads/Appartment Price Prediction/report_template.html", feature_names=None
    ):
        """G√©n√®re un rapport HTML r√©sumant les performances des mod√®les."""
        if not os.path.exists('templates'):
            os.makedirs('templates')
        
        # D√©finir le r√©pertoire o√π les graphiques sont enregistr√©s
        plots_dir = 'C:/Users/33766/models/plots'
        if not os.path.exists(plots_dir):
            os.makedirs(plots_dir)
        
        # Initialiser l'environnement Jinja2
        env = Environment(loader=FileSystemLoader('C:/Users/33766/Downloads/Appartment Price Prediction'))
        template = env.get_template('report_template.html')  # Assurez-vous que ce mod√®le existe dans le r√©pertoire courant
        
        models = rmse_scores.keys()
        plot_paths = {}
        
        for model in models:
            plot_paths[model] = {}
            # D√©finir les chemins relatifs pour diff√©rents graphiques
            pred_plot = os.path.join(plots_dir, f"{model}_predictions.png")
            resid_plot = os.path.join(plots_dir, f"{model}_residuals.png")
            feat_imp_plot = os.path.join(plots_dir, f"{model}_feature_importance.png")
            
            
            if os.path.exists(pred_plot):
                plot_paths[model]['predictions'] = pred_plot
            else:
                logging.warning(f"Graphique des pr√©dictions pour {model} introuvable √† {pred_plot}.")
                plot_paths[model]['predictions'] = ''
            
            if os.path.exists(resid_plot):
                plot_paths[model]['residuals'] = resid_plot
            else:
                logging.warning(f"Residuals plot for {model} not found at {resid_plot}.")
                plot_paths[model]['residuals'] = ''
            
            
            if os.path.exists(feat_imp_plot):
                plot_paths[model]['feature_importance'] = feat_imp_plot
            else:
                plot_paths[model]['feature_importance'] = None
        
        
        html_content = template.render(
            rmse_scores=rmse_scores,
            models=models,
            plot_paths=plot_paths
        )
        
        
        with open(report_path, 'w') as f:
            f.write(html_content)
        logging.info(f"Rapport automatis√© g√©n√©r√© √† {report_path}")
    
    @staticmethod
    def plot_predictions(y_true, y_pred, model_name, save_path):
        """Trace et enregistre les prix pr√©dits par rapport aux prix r√©els pour un mod√®le."""
        plt.figure(figsize=(12, 8))
        sns.scatterplot(x=y_true, y=y_pred, alpha=0.5, edgecolor='k')
        plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', linewidth=2)
        plt.title(f'{model_name} Prix Pr√©vus vs. Prix R√©els')
        plt.xlabel('Prix R√©els')
        plt.ylabel('Prix Pr√©vus')
        plt.tight_layout()
        plt.savefig(save_path)
        plt.close()
        logging.info(f"Graphique des prix pr√©vus vs. r√©els pour {model_name} enregistr√© dans {save_path}.")
    
    @staticmethod
    def plot_residuals(y_true, y_pred, model_name, save_path):
        """Trace et enregistre la distribution des r√©sidus pour un mod√®le."""
        residuals = y_true - y_pred
        plt.figure(figsize=(12, 8))
        sns.histplot(residuals, bins=50, kde=True, color='salmon')
        plt.title(f'{model_name} Distribution des R√©sidus')
        plt.xlabel('R√©sidus')
        plt.tight_layout()
        plt.savefig(save_path)
        plt.close()
        logging.info(f"Graphique de distribution des r√©sidus pour {model_name} enregistr√© dans {save_path}.")

```

</details>

**6. utils.py**

Fonctions utilitaires pour le calcul des m√©triques de r√©gression (RMSE, MAE, R¬≤) et pour la visualisation des performances des mod√®les.
                                                                  
<details> <summary>Voir le code</summary>

```python

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import logging
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from typing import List, Callable, Union

class Metrics:
    """Classe utilitaire pour les m√©triques de r√©gression courantes."""
    
    @staticmethod
    def rmse(y_true: pd.Series, y_pred: np.ndarray) -> float:
        """
        Calculer l'erreur quadratique moyenne (RMSE).
        """
        return np.sqrt(mean_squared_error(y_true, y_pred))

    @staticmethod
    def mae(y_true: pd.Series, y_pred: np.ndarray) -> float:
        """
        Calculer l'erreur absolue moyenne (MAE).
        """
        return mean_absolute_error(y_true, y_pred)

    @staticmethod
    def r2(y_true: pd.Series, y_pred: np.ndarray) -> float:
        """
        Calculer le coefficient de d√©termination (R¬≤).
        """
        return r2_score(y_true, y_pred)

    @staticmethod
    def custom_metric(y_true: pd.Series, y_pred: np.ndarray, metric_fn: Callable) -> float:
        """
        Calculer une m√©trique personnalis√©e fournie sous forme de fonction.
        
        Param√®tres:
            y_true (pd.Series): Valeurs cibles r√©elles.
            y_pred (np.ndarray): Valeurs cibles pr√©dites.
            metric_fn (Callable): Fonction prenant y_vrai et y_pred et renvoyant une m√©trique.
            
        Returns:
            float: R√©sultat de la m√©trique.
        """
        return metric_fn(y_true, y_pred)

class Visualization:
    """Classe utilitaire pour tracer les performances du mod√®le et l'importance des features."""
    
    @staticmethod
    def plot_feature_importance(model, feature_names: List[str], model_name: str, save_path: str = None):
        """
        Tracer l'importance des features pour les mod√®les bas√©s sur les arbres.
        """
        if not hasattr(model, 'feature_importances_'):
            logging.warning(f"{model_name} n'a pas l'attribut 'feature_importances_'.")
            return

        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1]

        plt.figure(figsize=(12, 8))
        plt.title(f"{model_name} Feature Importances")
        plt.bar(range(len(importances)), importances[indices], color='steelblue')
        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
        plt.xlabel('Features')
        plt.ylabel('Importance')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path)
            logging.info(f"Graphique d'importance des features pour {model_name} enregistr√© √† {save_path}")
        else:
            plt.show()

    @staticmethod
    def plot_residuals(y_true: pd.Series, y_pred: np.ndarray, model_name: str, save_path: str = None):
        """
        Tracer la distribution des r√©sidus pour les pr√©dictions.
        """
        residuals = y_true - y_pred
        plt.figure(figsize=(8, 6))
        plt.hist(residuals, bins=50, color='lightcoral', edgecolor='k')
        plt.xlabel('Residuals')
        plt.title(f'Distribution des R√©sidus - {model_name}')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path)
            logging.info(f"Graphique de distribution des r√©sidus pour {model_name} enregistr√© √† {save_path}")
        else:
            plt.show()

    @staticmethod
    def plot_model_performance(rmse_scores: dict, save_path: str = None):
        """
        Tracer les scores RMSE pour diff√©rents mod√®les.
        """
        if not rmse_scores:
            logging.warning("Aucun score RMSE fourni pour le trac√©.")
            return

        models = list(rmse_scores.keys())
        rmse_values = list(rmse_scores.values())

        plt.figure(figsize=(10, 6))
        bars = plt.bar(models, rmse_values, color='skyblue')
        plt.xlabel('Models')
        plt.ylabel('RMSE')
        plt.title('Comparaison des RMSE des Mod√®les')
        plt.xticks(rotation=45)
        plt.tight_layout()

        # Annoter les barres avec les valeurs RMSE
        for bar in bars:
            height = bar.get_height()
            plt.annotate(f'{height:.2f}',
                         xy=(bar.get_x() + bar.get_width() / 2, height),
                         xytext=(0, 3),
                         textcoords="offset points",
                         ha='center', va='bottom')

        if save_path:
            plt.savefig(save_path)
            logging.info(f"Graphique de performance des mod√®les enregistr√© √† {save_path}")
        else:
            plt.show()

class TensorFlowMetrics:
    """Classe utilitaire pour les m√©triques compatibles avec TensorFlow."""
    
    @staticmethod
    def root_mean_squared_error(y_true, y_pred) -> tf.Tensor:
        """
        Fonction de perte RMSE compatible avec TensorFlow.
        """
        return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))

```

</details>

**7. main.py**

Script principal pour ex√©cuter le pipeline de pr√©diction du prix des appartements.

<details> <summary>Voir le code</summary>

```python

import logging
import sys
import pandas as pd
from data_preparation import load_and_prepare_data
from model_training import train_and_evaluate_models
from config import FilePaths, LoggingConfig, FeatureSelectionParams
from utils import Metrics
from visualization import Visualization
import warnings

warnings.filterwarnings("ignore", message="main thread is not in main loop")

def setup_logging():
    """
    Configurer les param√®tres de journalisation.
    """
    logging.basicConfig(
        level=getattr(logging, LoggingConfig.LEVEL),
        format=LoggingConfig.FORMAT,
        handlers=[
            logging.FileHandler("prediction_prix_appartements.log"),
            logging.StreamHandler(sys.stdout)
        ]
    )
    logging.info("La journalisation est configur√©e.")

def process_data(X: pd.DataFrame, threshold: float, protected_features: list) -> pd.DataFrame:
    """
    Traiter les donn√©es en appliquant un seuil aux features prot√©g√©s.
    """
    processed_df = X.copy()
    # Appliquer un seuil uniquement aux features non-binaires existantes
    for feature in protected_features:
        if feature in processed_df.columns and processed_df[feature].nunique() > 2:
            processed_df[feature] = processed_df[feature].apply(lambda x: 1 if x > threshold else 0)
            logging.debug(f"Seuil appliqu√© √† la feature prot√©g√©e : {feature}")
        else:
            logging.info(f"Aucun seuil appliqu√© √† '{feature}' car elle est d√©j√† binaire ou non pr√©sente.")
    return processed_df

def main():
    """
    Fonction principale pour ex√©cuter le pipeline de pr√©diction du prix des appartements.
    """
    setup_logging()
    logging.info("D√©marrage du pipeline de pr√©diction de prix des appartements...")

    # D√©finir les coordonn√©es du centre-ville
    city_center = (2.3522, 48.8566)  # Centre-ville de Paris (longitude, latitude)

    # Charger et pr√©traiter les donn√©es
    try:
        X_train, y_train, X_test, y_test = load_and_prepare_data(FilePaths.DATA_FILE_PATH, center_coordinates=city_center)
        logging.info(f"Donn√©es charg√©es et divis√©es : X_train={X_train.shape}, X_test={X_test.shape}")
    except FileNotFoundError as e:
        logging.error(f"√âchec du chargement des donn√©es : {e}")
        sys.exit(1)
    except KeyError as e:
        logging.error(f"√âchec du pr√©traitement des donn√©es : {e}")
        sys.exit(1)
    except Exception as e:
        logging.error(f"Erreur inattendue lors du chargement des donn√©es : {e}")
        sys.exit(1)

    # D√©finir les features prot√©g√©es et le seuil depuis la config ou les param√®tres
    protected_features = ['meuble_binary']
    threshold = FeatureSelectionParams.THRESHOLD

    # Traiter les donn√©es d'entra√Ænement
    try:
        processed_train_df = process_data(X_train, threshold=threshold, protected_features=protected_features)
        logging.info(f"Forme des donn√©es d'entra√Ænement trait√©es : {processed_train_df.shape}")
    except Exception as e:
        logging.error(f"Erreur lors du traitement des donn√©es d'entra√Ænement : {e}")
        sys.exit(1)

    # Traiter les donn√©es de test
    try:
        processed_test_df = process_data(X_test, threshold=threshold, protected_features=protected_features)
        logging.info(f"Forme des donn√©es de test trait√©es : {processed_test_df.shape}")
    except Exception as e:
        logging.error(f"Erreur lors du traitement des donn√©es de test : {e}")
        sys.exit(1)

    # Entra√Æner et √©valuer les mod√®les
    try:
        model_rmse_scores, model_predictions = train_and_evaluate_models(
            processed_train_df, y_train, processed_test_df, y_test
        )
    except Exception as e:
        logging.error(f"√âchec de l'entra√Ænement et de l'√©valuation des mod√®les : {e}")
        sys.exit(1)

    # Journaliser les scores RMSE finaux
    logging.info("Scores RMSE finaux des mod√®les :")
    for model, score in model_rmse_scores.items():
        logging.info(f"{model}: RMSE = {score:.4f}")

    logging.info("Pipeline de pr√©diction de prix des appartements termin√© avec succ√®s.")

    # G√©n√©rer un rapport automatis√©
    try:
        Visualization.generate_automated_report(
            rmse_scores=model_rmse_scores,
            model_predictions=model_predictions,
            y_test=y_test,
            report_path="models/automated_model_report.html",
            feature_names=processed_train_df.columns.tolist()  # Utiliser les noms des features des donn√©es d'entra√Ænement trait√©es
        )
        logging.info("Rapport automatis√© g√©n√©r√© avec succ√®s.")
    except Exception as e:
        logging.error(f"√âchec de la g√©n√©ration du rapport automatis√© : {e}")

if __name__ == "__main__":
    main()

```
</details>

**8. automated_model_report.html**

Mod√®le HTML utilis√© pour g√©n√©rer le rapport automatis√© pr√©sentant les performances des mod√®les.

<details> <summary>Voir le code</summary>

```html

<!DOCTYPE html>
<html>
<head>
    <title>Rapport Automatis√© de Performance des Mod√®les</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        h1, h2, h3 { color: #333; }
        table { width: 60%; border-collapse: collapse; margin-bottom: 40px; }
        th, td { border: 1px solid #ccc; padding: 12px; text-align: center; }
        th { background-color: #f4f4f4; }
        img { max-width: 100%; height: auto; margin-bottom: 40px; }
        .section { margin-bottom: 60px; }
    </style>
</head>
<body>
    <h1>Rapport Automatis√© de Performance des Mod√®les</h1>

    <!-- Section 1: RMSE Scores -->
    <div class="section">
        <h2>1. Scores RMSE</h2>
        <table>
            <tr>
                <th>Mod√®le</th>
                <th>RMSE</th>
            </tr>
            
            <tr>
                <td>Lin√©aire</td>
                <td>1.8928</td>
            </tr>
            
            <tr>
                <td>Arbre de D√©cision</td>
                <td>1.6156</td>
            </tr>
            
            <tr>
                <td>For√™t Al√©atoire</td>
                <td>1.6138</td>
            </tr>
            
            <tr>
                <td>Gradient Boosting</td>
                <td>1.5979</td>
            </tr>
            
            <tr>
                <td>Extra Trees</td>
                <td>1.6083</td>
            </tr>
            
            <tr>
                <td>XGBoost</td>
                <td>1.5933</td>
            </tr>
            
            <tr>
                <td>LightGBM</td>
                <td>1.5890</td>
            </tr>
            
            <tr>
                <td>MLP</td>
                <td>1.6164</td>
            </tr>
            
            <tr>
                <td>DNN</td>
                <td>1.6254</td>
            </tr>
            
            <tr>
                <td>Ensemble</td>
                <td>1.5945</td>
            </tr>
            
        </table>
    </div>

    <!-- Section 2: Pr√©dictions vs Prix R√©els -->
    <div class="section">
        <h2>2. Pr√©dictions vs Prix R√©els</h2>
        
            <h3>Pr√©dictions Lin√©aires vs R√©els</h3>
            <p><strong>Pr√©dictions Lin√©aires</strong></p>
            
                <img src="C:/Users/33766/models/plots\Linear_predictions.png" alt="Linear Predictions">
            
        
            <h3>Pr√©dictions Arbre de D√©cision vs R√©els</h3>
            <p><strong>Pr√©dictions Arbre de D√©cision</strong></p>
            
                <img src="C:/Users/33766/models/plots\DecisionTree_predictions.png" alt="DecisionTree Predictions">
            
        
            <h3>Pr√©dictions For√™t Al√©atoire vs R√©els</h3>
            <p><strong>Pr√©dictions For√™t Al√©atoire</strong></p>
            
                <img src="C:/Users/33766/models/plots\RandomForest_predictions.png" alt="RandomForest Predictions">
            
        
            <h3>Pr√©dictions Gradient Boosting vs R√©els</h3>
            <p><strong>Pr√©dictions Gradient Boosting</strong></p>
            
                <img src="C:/Users/33766/models/plots\GradientBoosting_predictions.png" alt="GradientBoosting Predictions">
            
        
            <h3>Pr√©dictions Extra Trees vs R√©els</h3>
            <p><strong>Pr√©dictions Extra Trees</strong></p>
            
                <img src="C:/Users/33766/models/plots\ExtraTrees_predictions.png" alt="ExtraTrees Predictions">
            
        
            <h3>Pr√©dictions XGBoost vs R√©els</h3>
            <p><strong>Pr√©dictions XGBoost</strong></p>
            
                <img src="C:/Users/33766/models/plots\XGBoost_predictions.png" alt="XGBoost Predictions">
            
        
            <h3>Pr√©dictions LightGBM vs R√©els</h3>
            <p><strong>Pr√©dictions LightGBM</strong></p>
            
                <img src="C:/Users/33766/models/plots\LightGBM_predictions.png" alt="LightGBM Predictions">
            
        
            <h3>Pr√©dictions MLP vs R√©els</h3>
            <p><strong>MLP Predictions</strong></p>
            
                <img src="C:/Users/33766/models/plots\MLP_predictions.png" alt="MLP Predictions">
            
        
            <h3>Pr√©dictions DNN vs R√©els</h3>
            <p><strong>DNN Predictions</strong></p>
            
                <img src="C:/Users/33766/models/plots\DNN_predictions.png" alt="DNN Predictions">
            
        
            <h3>Pr√©dictions Ensemble vs R√©els</h3>
            <p><strong>Pr√©dictions Ensemble</strong></p>
            
                <img src="C:/Users/33766/models/plots\Ensemble_predictions.png" alt="Ensemble Predictions">
            
        
    </div>

    <!-- Section 3: Distribution des R√©sidus -->
    <div class="section">
        <h2>3. Distribution des R√©sidus</h2>
        
            <h3>R√©sidus Lin√©aires</h3>
            <p><strong>R√©sidus Lin√©aires</strong></p>
            
                <img src="C:/Users/33766/models/plots\Linear_residuals.png" alt="Linear Residuals">
            
        
            <h3>R√©sidus Arbre de D√©cision</h3>
            <p><strong>R√©sidus Arbre de D√©cision</strong></p>
            
                <img src="C:/Users/33766/models/plots\DecisionTree_residuals.png" alt="DecisionTree Residuals">
            
        
            <h3>R√©sidus For√™t Al√©atoire</h3>
            <p><strong>R√©sidus For√™t Al√©atoire</strong></p>
            
                <img src="C:/Users/33766/models/plots\RandomForest_residuals.png" alt="RandomForest Residuals">
            
        
            <h3>R√©sidus Gradient Boosting</h3>
            <p><strong>R√©sidus Gradient Boosting</strong></p>
            
                <img src="C:/Users/33766/models/plots\GradientBoosting_residuals.png" alt="GradientBoosting Residuals">
            
        
            <h3>R√©sidus Extra Trees</h3>
            <p><strong>R√©sidus Extra Trees</strong></p>
            
                <img src="C:/Users/33766/models/plots\ExtraTrees_residuals.png" alt="ExtraTrees Residuals">
            
        
            <h3>R√©sidus XGBoost</h3>
            <p><strong>R√©sidus XGBoost</strong></p>
            
                <img src="C:/Users/33766/models/plots\XGBoost_residuals.png" alt="XGBoost Residuals">
            
        
            <h3>R√©sidus LightGBM</h3>
            <p><strong>R√©sidus LightGBM</strong></p>
            
                <img src="C:/Users/33766/models/plots\LightGBM_residuals.png" alt="LightGBM Residuals">
            
        
            <h3>R√©sidus MLP</h3>
            <p><strong>R√©sidus MLP</strong></p>
            
                <img src="C:/Users/33766/models/plots\MLP_residuals.png" alt="MLP Residuals">
            
        
            <h3>R√©sidus DNN</h3>
            <p><strong>R√©sidus DNN</strong></p>
            
                <img src="C:/Users/33766/models/plots\DNN_residuals.png" alt="DNN Residuals">
            
        
            <h3>R√©sidus Ensemble</h3>
            <p><strong>R√©sidus Ensemble</strong></p>
            
                <img src="C:/Users/33766/models/plots\Ensemble_residuals.png" alt="Ensemble Residuals">
            
        
    </div>

    <!-- Section 4: Importances des Caract√©ristiques -->
    <div class="section">
        <h2>4. Importances des Caract√©ristiques</h2>
        
            <h3>Importances des Caract√©ristiques Lin√©aires</h3>
            
                <img src="C:/Users/33766/models/plots\Linear_feature_importance.png" alt="Linear Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques Arbre de D√©cision</h3>
            
                <img src="C:/Users/33766/models/plots\DecisionTree_feature_importance.png" alt="DecisionTree Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques For√™t Al√©atoire</h3>
            
                <img src="C:/Users/33766/models/plots\RandomForest_feature_importance.png" alt="RandomForest Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques Gradient Boosting</h3>
            
                <img src="C:/Users/33766/models/plots\GradientBoosting_feature_importance.png" alt="GradientBoosting Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques Extra Trees</h3>
            
                <img src="C:/Users/33766/models/plots\ExtraTrees_feature_importance.png" alt="ExtraTrees Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques XGBoost</h3>
            
                <img src="C:/Users/33766/models/plots\XGBoost_feature_importance.png" alt="XGBoost Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques LightGBM</h3>
            
                <img src="C:/Users/33766/models/plots\LightGBM_feature_importance.png" alt="LightGBM Feature Importance">
            
        
            <h3>Importances des Caract√©ristiques MLP</h3>
            
                <p><em>Aucune importance des caract√©ristiques disponible pour MLP</em></p>
            
        
            <h3>Importances des Caract√©ristiques DNN</h3>
            
                <p><em>Aucune importance des caract√©ristiques disponible pour DNN</em></p>
            
        
            <h3>Importances des Caract√©ristiques Ensemble</h3>
            
                <p><em>Aucune importance des caract√©ristiques disponible pour Ensemble</em></p>
            
        
    </div>
</body>
</html>

```
</details>

## Instructions d'Installation et d'Ex√©cution

**Pr√©requis**

**Python** 3.7 ou sup√©rieur
**pip** install√©

## Installation des D√©pendances

```
pip install -r requirements.txt
```

## Ex√©cution du Projet

Pour ex√©cuter l'ensemble du pipeline, y compris la pr√©paration des donn√©es, l'ing√©nierie des features, l'entra√Ænement des mod√®les et la g√©n√©ration des visualisations et du rapport, lancez simplement le script principal :

```
python main.py
```

Ce script ex√©cutera toutes les √©tapes n√©cessaires et g√©n√©rera les mod√®les entra√Æn√©s, les visualisations et le rapport automatis√©.

## R√©sultats des Mod√®les

Les performances des diff√©rents mod√®les de r√©gression ont √©t√© √©valu√©es √† l'aide de la m√©trique RMSE (Root Mean Squared Error). Un RMSE plus faible indique une meilleure pr√©cision des pr√©dictions.

| Mod√®le                            | RMSE            | 
|-----------------------------------|-----------------|
| R√©gression Lin√©aire               | 1.8928          |
| Arbre de D√©cision                 | 1.6156          | 
| For√™t Al√©atoire                   | 1.6138          | 
| Gradient Boosting                 | 1.5979          |
| Extra Trees                       | 1.6083          | 
| XGBoost                           | 1.5933          | 
| LightGBM                          | 1.5890          | 
| MLP (Perceptron Multi-couche)     | 1.6164          | 
| DNN (R√©seau de Neurones Profonds) | 1.6254          | 
| Ensemble (Voting Regressor)       | 1.5945          |

### Interpr√©tation des R√©sultats

**Meilleures Performances :** Les mod√®les bas√©s sur le boosting, en particulier LightGBM et XGBoost, ont obtenu les meilleurs scores de RMSE, indiquant une excellente capacit√© √† capturer les relations complexes dans les donn√©es.

**Approche Ensembliste :** Le mod√®le Ensemble, combinant plusieurs mod√®les via un Voting Regressor, a √©galement obtenu un RMSE comp√©titif, d√©montrant l'efficacit√© de l'agr√©gation des mod√®les.

**Mod√®les Lin√©aires et Simples :** La r√©gression lin√©aire a le RMSE le plus √©lev√©, sugg√©rant qu'un mod√®le lin√©aire simple est moins adapt√© pour ce type de donn√©es.

## Explication des Visualisations

### 1.Graphiques de Pr√©dictions vs R√©el

**Objectif :** Visualiser la pr√©cision des pr√©dictions de chaque mod√®le en comparant les valeurs pr√©dites aux valeurs r√©elles.

**Interpr√©tation :** Un alignement proche de la diagonale indique des pr√©dictions pr√©cises.

### 2.Distribution des R√©sidus

**Objectif :** Illustrer les erreurs de pr√©diction pour v√©rifier si elles sont distribu√©es normalement autour de z√©ro.

**Interpr√©tation :** Une distribution centr√©e autour de z√©ro sans biais indique un mod√®le bien ajust√©.

### 3.Importance des Caract√©ristiques

**Objectif :** Identifier les variables qui influencent le plus les pr√©dictions du mod√®le.

**Interpr√©tation :** Les variables avec une importance √©lev√©e sont des facteurs cl√©s dans la variation des prix des appartements.

## Conclusion

Ce projet d√©montre l'efficacit√© des techniques de r√©gression avanc√©es pour pr√©dire les prix des appartements √† Paris en se basant sur divers facteurs g√©ographiques et caract√©ristiques des propri√©t√©s. Les mod√®les bas√©s sur le boosting, tels que LightGBM et XGBoost, se sont av√©r√©s √™tre les plus performants, obtenant les meilleurs scores de RMSE. L'approche ensembliste, qui combine plusieurs mod√®les, a √©galement montr√© de bons r√©sultats, renfor√ßant l'id√©e que l'agr√©gation de mod√®les peut am√©liorer la pr√©cision des pr√©dictions.

Gr√¢ce aux visualisations et aux rapports g√©n√©r√©s, les utilisateurs peuvent non seulement obtenir des pr√©dictions pr√©cises, mais aussi mieux comprendre les facteurs influen√ßant les prix immobiliers. Cela permet de prendre des d√©cisions inform√©es, que ce soit pour l'achat, la vente ou l'√©valuation des biens immobiliers √† Paris.
